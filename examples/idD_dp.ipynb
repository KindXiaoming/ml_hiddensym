{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1874f5e3070>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Force Field\n",
    "def f(x):\n",
    "    m1 = 1; m2 = 1; g = 1; l1 = 1; l2 = 1\n",
    "    a1 = x[:,0]/torch.sqrt(torch.tensor(g,dtype=torch.float))\n",
    "    w1 = x[:,1]\n",
    "    a2 = x[:,2]/torch.sqrt(torch.tensor(g,dtype=torch.float))\n",
    "    w2 = x[:,3]\n",
    "    beta1 = (m2*l1*w1**2*torch.sin(a2-a1)*torch.cos(a2-a1)+m2*g*torch.sin(a2)*torch.cos(a2-a1)+m2*l2*w2**2*torch.sin(a2-a1)-(m1+m2)*g*torch.sin(a1))/((m1+m2)*l1-m2*l1*torch.cos(a2-a1)**2)\n",
    "    beta2 = (-m2*l2*w2**2*torch.sin(a2-a1)*torch.cos(a2-a1)+(m1+m2)*(g*torch.sin(a1)*torch.cos(a2-a1)-l1*w1**2*torch.sin(a2-a1)-g*torch.sin(a2)))/((m1+m2)*l1-m2*l1*torch.cos(a2-a1)**2)\n",
    "    return torch.transpose(torch.stack([torch.sqrt(torch.tensor(g,dtype=torch.float))*w1,beta1,torch.sqrt(torch.tensor(g,dtype=torch.float))*w2,beta2]),0,1)\n",
    "\n",
    "\n",
    "input_ = torch.normal(0,1,size=(1000,4), requires_grad=True)*0.1\n",
    "#input_ = (torch.rand(1000,4, requires_grad=True)-0.5)*2*1\n",
    "\n",
    "input_d = input_.shape[1]\n",
    "\n",
    "def batch_jacobian(func, x, create_graph=False):\n",
    "    # x in shape (Batch, Length)\n",
    "    def _func_sum(x):\n",
    "        return func(x).sum(dim=0)\n",
    "    return torch.autograd.functional.jacobian(_func_sum, x, create_graph=create_graph).permute(1,0,2)\n",
    "\n",
    "# Define Transformer\n",
    "\n",
    "class T(nn.Module):\n",
    "    def __init__(self,w=200):\n",
    "        super(T, self).__init__()\n",
    "        self.l1 = nn.Linear(input_d,w)\n",
    "        self.l2 = nn.Linear(w,w)\n",
    "        self.l23 = nn.Linear(w,w)\n",
    "        self.l3 = nn.Linear(w,input_d)\n",
    "    \n",
    "    def forward(self, x, eps=1.0):\n",
    "        bs = x.shape[0]\n",
    "        #f = nn.Tanh()\n",
    "        f = nn.SiLU()\n",
    "        self.x1 = f(self.l1(x))\n",
    "        self.x2 = f(self.l2(self.x1))\n",
    "        self.x23 = f(self.l23(self.x2))\n",
    "        self.x3 = self.l3(self.x23)\n",
    "        return x + eps*self.x3\n",
    "    \n",
    "    #def forward(self, x, eps=0.0):\n",
    "    #    return self.l0(x)\n",
    "    \n",
    "    def transform_f(self, x):\n",
    "        jac_ts = batch_jacobian(self.forward, x, create_graph=True)\n",
    "        return torch.matmul(jac_ts, torch.unsqueeze(f(x), dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss library\n",
    "\n",
    "# Lie group: for SO(2), g_J = [[0,1],[-1,0]]\n",
    "\n",
    "def Jp_(f,t,inputs):\n",
    "    input_d = input_.shape[1]\n",
    "    jac_f = batch_jacobian(f,inputs,create_graph=True)\n",
    "    jac_ts = batch_jacobian(t,inputs,create_graph=True)\n",
    "    jac_inv_ts = torch.inverse(jac_ts)\n",
    "\n",
    "    # get Hessian of t\n",
    "    gradsss = []\n",
    "    for i in range(input_d):\n",
    "        gradss = []\n",
    "        for j in range(input_d):\n",
    "            grads = torch.autograd.grad(jac_ts[:,i,j], inputs, torch.ones_like(jac_ts[:,i,j]), create_graph=True, retain_graph=True)[0]\n",
    "            gradss.append(grads)\n",
    "        gradss = torch.stack(gradss)\n",
    "        gradsss.append(gradss)\n",
    "    # SHAPE\n",
    "    hess_t = torch.stack(gradsss).permute(2,0,1,3)\n",
    "\n",
    "    # calculate J'\n",
    "    Jp1 = jac_inv_ts.permute(0,2,1).unsqueeze(dim=1).unsqueeze(dim=4)*hess_t.permute(0,2,1,3).unsqueeze(dim=2)*f(inputs).unsqueeze(dim=1).unsqueeze(dim=2).unsqueeze(dim=3)\n",
    "    Jp2 = jac_inv_ts.permute(0,2,1).unsqueeze(dim=1).unsqueeze(dim=4)*jac_ts.unsqueeze(dim=2).unsqueeze(dim=3)*jac_f.permute(0,2,1).unsqueeze(dim=1).unsqueeze(dim=2)\n",
    "    Jp = Jp1 + Jp2\n",
    "    Jp = torch.sum(torch.sum(Jp,dim=4),dim=3)\n",
    "    return Jp\n",
    "\n",
    "def hess(t, inputs):\n",
    "    jac_ts = batch_jacobian(t,inputs,create_graph=True)\n",
    "    \n",
    "    # get Hessian of t\n",
    "    gradsss = []\n",
    "    for i in range(input_d):\n",
    "        gradss = []\n",
    "        for j in range(input_d):\n",
    "            grads = torch.autograd.grad(jac_ts[:,i,j], inputs, torch.ones_like(jac_ts[:,i,j]), create_graph=True, retain_graph=True)[0]\n",
    "            gradss.append(grads)\n",
    "        gradss = torch.stack(gradss)\n",
    "        gradsss.append(gradss)\n",
    "    # SHAPE\n",
    "    hess_t = torch.stack(gradsss).permute(2,0,1,3)\n",
    "    \n",
    "    return hess_t\n",
    "    \n",
    "\n",
    "def off_diag(M,n_part=[2,2]):\n",
    "    bs = M.shape[0]\n",
    "    input_d = M.shape[1]\n",
    "    assert input_d == np.sum(n_part)\n",
    "    start = 0\n",
    "    end = n_part[0]\n",
    "    diag_loss = 0\n",
    "    for i in range(len(n_part)):\n",
    "        diag_loss = diag_loss + torch.sum(M[:,start:end, start:end]**2)\n",
    "        start = end\n",
    "        end = end + n_part[i]\n",
    "    return (torch.sum(M**2) - diag_loss)/(batch_size*input_d**2)\n",
    "\n",
    "\n",
    "def lie_loss(f,t,inputs):\n",
    "    \n",
    "    bs = inputs.shape[0]\n",
    "    # for SO(2)\n",
    "    g_J = torch.tensor([[0,1],[-1,0]], dtype=torch.float, requires_grad=True)\n",
    "    Jp = Jp_(f,t,inputs)\n",
    "    fp = t.transform_f(inputs)\n",
    "    inputsp = torch.unsqueeze(t(inputs), dim=2)\n",
    "    \n",
    "    g_J = torch.unsqueeze(torch.unsqueeze(torch.ones(bs,),dim=1),dim=1) * torch.unsqueeze(g_J, dim=0)\n",
    "    pde = torch.matmul(torch.matmul(Jp.permute(0,1,2),g_J),inputsp) - torch.matmul(g_J, fp)\n",
    "    r_mse = torch.mean(inputsp**2)\n",
    "    loss = torch.mean(pde**2)\n",
    "    return loss/r_mse\n",
    "\n",
    "def translation_loss(f,t,inputs):\n",
    "    Jp = Jp_(f,t,inputs)[:,0]\n",
    "    loss = torch.mean(Jp**2)\n",
    "    return loss\n",
    "\n",
    "def modularity_loss(f,t,inputs,n_part=[2,2]):\n",
    "    Jp = Jp_(f,t,inputs)\n",
    "    loss = off_diag(Jp,n_part=n_part)\n",
    "    return loss\n",
    "\n",
    "def hamiltonicity_loss(f,t,inputs):\n",
    "    Jp = Jp_(f,t,inputs)\n",
    "    input_d = inputs.shape[1]\n",
    "    assert input_d % 2 ==0\n",
    "    M = torch.zeros(input_d, input_d)\n",
    "    half_d = int(input_d/2)\n",
    "    M[:half_d, half_d:] = torch.eye(half_d)\n",
    "    M[half_d:, :half_d] = -torch.eye(half_d)\n",
    "    M = torch.tensor(M, dtype=torch.float, requires_grad=True)\n",
    "    JMMJ = torch.matmul(Jp.permute(0,2,1), M) + torch.matmul(M, Jp)\n",
    "    loss = torch.mean(JMMJ**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Loss_ham: 0.7399 | Loss_mod: nan\n",
      "Epoch:  10 | Loss_ham: 0.1201 | Loss_mod: nan\n",
      "Epoch:  20 | Loss_ham: 0.1360 | Loss_mod: nan\n",
      "Epoch:  30 | Loss_ham: 0.0767 | Loss_mod: nan\n",
      "Epoch:  40 | Loss_ham: 0.0692 | Loss_mod: nan\n",
      "Epoch:  50 | Loss_ham: 0.0501 | Loss_mod: nan\n",
      "Epoch:  60 | Loss_ham: 0.0462 | Loss_mod: nan\n",
      "Epoch:  70 | Loss_ham: 0.0282 | Loss_mod: nan\n",
      "Epoch:  80 | Loss_ham: 0.0057 | Loss_mod: nan\n",
      "Epoch:  90 | Loss_ham: 0.0033 | Loss_mod: nan\n",
      "Epoch:  100 | Loss_ham: 0.0016 | Loss_mod: nan\n",
      "Epoch:  110 | Loss_ham: 0.0013 | Loss_mod: nan\n",
      "Epoch:  120 | Loss_ham: 0.0012 | Loss_mod: nan\n",
      "Epoch:  130 | Loss_ham: 0.0008 | Loss_mod: nan\n",
      "Epoch:  140 | Loss_ham: 0.0009 | Loss_mod: nan\n",
      "Epoch:  150 | Loss_ham: 0.0010 | Loss_mod: nan\n",
      "Epoch:  160 | Loss_ham: 0.0008 | Loss_mod: nan\n",
      "Epoch:  170 | Loss_ham: 0.0007 | Loss_mod: nan\n",
      "Epoch:  180 | Loss_ham: 0.0008 | Loss_mod: nan\n",
      "Epoch:  190 | Loss_ham: 0.0007 | Loss_mod: nan\n",
      "Epoch:  200 | Loss_ham: 0.0006 | Loss_mod: nan\n",
      "Epoch:  210 | Loss_ham: 0.0008 | Loss_mod: nan\n",
      "Epoch:  220 | Loss_ham: 0.0009 | Loss_mod: nan\n",
      "Epoch:  230 | Loss_ham: 0.0009 | Loss_mod: nan\n",
      "Epoch:  240 | Loss_ham: 0.0007 | Loss_mod: nan\n",
      "Epoch:  250 | Loss_ham: 0.0008 | Loss_mod: nan\n",
      "Epoch:  260 | Loss_ham: 0.0006 | Loss_mod: nan\n",
      "Epoch:  270 | Loss_ham: 0.0009 | Loss_mod: nan\n",
      "Epoch:  280 | Loss_ham: 0.0007 | Loss_mod: nan\n",
      "Epoch:  290 | Loss_ham: 0.0007 | Loss_mod: nan\n",
      "Epoch:  300 | Loss_ham: 0.0009 | Loss_mod: nan\n",
      "Epoch:  310 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  320 | Loss_ham: 0.0007 | Loss_mod: nan\n",
      "Epoch:  330 | Loss_ham: 0.0008 | Loss_mod: nan\n",
      "Epoch:  340 | Loss_ham: 0.0008 | Loss_mod: nan\n",
      "Epoch:  350 | Loss_ham: 0.0006 | Loss_mod: nan\n",
      "Epoch:  360 | Loss_ham: 0.0007 | Loss_mod: nan\n",
      "Epoch:  370 | Loss_ham: 0.0007 | Loss_mod: nan\n",
      "Epoch:  380 | Loss_ham: 0.0007 | Loss_mod: nan\n",
      "Epoch:  390 | Loss_ham: 0.0006 | Loss_mod: nan\n",
      "Epoch:  400 | Loss_ham: 0.0007 | Loss_mod: nan\n",
      "Epoch:  410 | Loss_ham: 0.0007 | Loss_mod: nan\n",
      "Epoch:  420 | Loss_ham: 0.0006 | Loss_mod: nan\n",
      "Epoch:  430 | Loss_ham: 0.0009 | Loss_mod: nan\n",
      "Epoch:  440 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  450 | Loss_ham: 0.0006 | Loss_mod: nan\n",
      "Epoch:  460 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  470 | Loss_ham: 0.0007 | Loss_mod: nan\n",
      "Epoch:  480 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  490 | Loss_ham: 0.0007 | Loss_mod: nan\n",
      "Epoch:  500 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  510 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  520 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  530 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  540 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  550 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  560 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  570 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  580 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  590 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  600 | Loss_ham: 0.0006 | Loss_mod: nan\n",
      "Epoch:  610 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  620 | Loss_ham: 0.0006 | Loss_mod: nan\n",
      "Epoch:  630 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  640 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  650 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  660 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  670 | Loss_ham: 0.0006 | Loss_mod: nan\n",
      "Epoch:  680 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  690 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  700 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  710 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  720 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  730 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  740 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  750 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  760 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  770 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  780 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  790 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  800 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  810 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  820 | Loss_ham: 0.0006 | Loss_mod: nan\n",
      "Epoch:  830 | Loss_ham: 0.0006 | Loss_mod: nan\n",
      "Epoch:  840 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  850 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  860 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  870 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  880 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  890 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  900 | Loss_ham: 0.0006 | Loss_mod: nan\n",
      "Epoch:  910 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  920 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  930 | Loss_ham: 0.0006 | Loss_mod: nan\n",
      "Epoch:  940 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  950 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  960 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  970 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  980 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  990 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  1000 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1010 | Loss_ham: 0.0020 | Loss_mod: nan\n",
      "Epoch:  1020 | Loss_ham: 0.0007 | Loss_mod: nan\n",
      "Epoch:  1030 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  1040 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  1050 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  1060 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1070 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  1080 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1090 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  1100 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  1110 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1120 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  1130 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1140 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  1150 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1160 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1170 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1180 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1190 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1200 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1210 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1220 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1230 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1240 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1250 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  1260 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1270 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1280 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1290 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1300 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  1310 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1320 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1330 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1340 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1350 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1360 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1370 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1380 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1390 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1400 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1410 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1420 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1430 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1440 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1450 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1460 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1470 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1480 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1490 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  1500 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1510 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1520 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1530 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  1540 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1550 | Loss_ham: 0.0005 | Loss_mod: nan\n",
      "Epoch:  1560 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1570 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1580 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1590 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1600 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1610 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1620 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1630 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1640 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  1650 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1660 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1670 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1680 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1690 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1700 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1710 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1720 | Loss_ham: 0.0003 | Loss_mod: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1730 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1740 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1750 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1760 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1770 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1780 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1790 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1800 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1810 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1820 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1830 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1840 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1850 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1860 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1870 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1880 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1890 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1900 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1910 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1920 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1930 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1940 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1950 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1960 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1970 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  1980 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  1990 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  2000 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2010 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2020 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  2030 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  2040 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2050 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2060 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2070 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2080 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2090 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2100 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  2110 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2120 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2130 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2140 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  2150 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  2160 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2170 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2180 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  2190 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2200 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2210 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2220 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  2230 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2240 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  2250 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2260 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  2270 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  2280 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  2290 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  2300 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  2310 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  2320 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  2330 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2340 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2350 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  2360 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  2370 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2380 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2390 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2400 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2410 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2420 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2430 | Loss_ham: 0.0002 | Loss_mod: nan\n",
      "Epoch:  2440 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2450 | Loss_ham: 0.0004 | Loss_mod: nan\n",
      "Epoch:  2460 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2470 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2480 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2490 | Loss_ham: 0.0003 | Loss_mod: nan\n",
      "Epoch:  2500 | Loss_ham: 0.0002 | Loss_mod: 0.1056\n",
      "Epoch:  2510 | Loss_ham: 0.0475 | Loss_mod: 0.0784\n",
      "Epoch:  2520 | Loss_ham: 0.0083 | Loss_mod: 0.0386\n",
      "Epoch:  2530 | Loss_ham: 0.0064 | Loss_mod: 0.0205\n",
      "Epoch:  2540 | Loss_ham: 0.0030 | Loss_mod: 0.0107\n",
      "Epoch:  2550 | Loss_ham: 0.0876 | Loss_mod: 0.0109\n",
      "Epoch:  2560 | Loss_ham: 0.0024 | Loss_mod: 0.0105\n",
      "Epoch:  2570 | Loss_ham: 0.0034 | Loss_mod: 0.0105\n",
      "Epoch:  2580 | Loss_ham: 0.0024 | Loss_mod: 0.0098\n",
      "Epoch:  2590 | Loss_ham: 0.0006 | Loss_mod: 0.0080\n",
      "Epoch:  2600 | Loss_ham: 0.0009 | Loss_mod: 0.0064\n",
      "Epoch:  2610 | Loss_ham: 0.0005 | Loss_mod: 0.0055\n",
      "Epoch:  2620 | Loss_ham: 0.0007 | Loss_mod: 0.0047\n",
      "Epoch:  2630 | Loss_ham: 0.0006 | Loss_mod: 0.0041\n",
      "Epoch:  2640 | Loss_ham: 0.0021 | Loss_mod: 0.0038\n",
      "Epoch:  2650 | Loss_ham: 0.0065 | Loss_mod: 0.0049\n",
      "Epoch:  2660 | Loss_ham: 0.0051 | Loss_mod: 0.0052\n",
      "Epoch:  2670 | Loss_ham: 0.0029 | Loss_mod: 0.0055\n",
      "Epoch:  2680 | Loss_ham: 0.0008 | Loss_mod: 0.0051\n",
      "Epoch:  2690 | Loss_ham: 0.0006 | Loss_mod: 0.0049\n",
      "Epoch:  2700 | Loss_ham: 0.0005 | Loss_mod: 0.0043\n",
      "Epoch:  2710 | Loss_ham: 0.0006 | Loss_mod: 0.0040\n",
      "Epoch:  2720 | Loss_ham: 0.0005 | Loss_mod: 0.0037\n",
      "Epoch:  2730 | Loss_ham: 0.0005 | Loss_mod: 0.0033\n",
      "Epoch:  2740 | Loss_ham: 0.0005 | Loss_mod: 0.0031\n",
      "Epoch:  2750 | Loss_ham: 0.0004 | Loss_mod: 0.0029\n",
      "Epoch:  2760 | Loss_ham: 0.0263 | Loss_mod: 0.0027\n",
      "Epoch:  2770 | Loss_ham: 0.0033 | Loss_mod: 0.0035\n",
      "Epoch:  2780 | Loss_ham: 0.0037 | Loss_mod: 0.0035\n",
      "Epoch:  2790 | Loss_ham: 0.0005 | Loss_mod: 0.0034\n",
      "Epoch:  2800 | Loss_ham: 0.0008 | Loss_mod: 0.0034\n",
      "Epoch:  2810 | Loss_ham: 0.0005 | Loss_mod: 0.0031\n",
      "Epoch:  2820 | Loss_ham: 0.0006 | Loss_mod: 0.0030\n",
      "Epoch:  2830 | Loss_ham: 0.0005 | Loss_mod: 0.0028\n",
      "Epoch:  2840 | Loss_ham: 0.0005 | Loss_mod: 0.0028\n",
      "Epoch:  2850 | Loss_ham: 0.0006 | Loss_mod: 0.0025\n",
      "Epoch:  2860 | Loss_ham: 0.0153 | Loss_mod: 0.0026\n",
      "Epoch:  2870 | Loss_ham: 0.0020 | Loss_mod: 0.0027\n",
      "Epoch:  2880 | Loss_ham: 0.0012 | Loss_mod: 0.0027\n",
      "Epoch:  2890 | Loss_ham: 0.0012 | Loss_mod: 0.0027\n",
      "Epoch:  2900 | Loss_ham: 0.0007 | Loss_mod: 0.0026\n",
      "Epoch:  2910 | Loss_ham: 0.0006 | Loss_mod: 0.0024\n",
      "Epoch:  2920 | Loss_ham: 0.0003 | Loss_mod: 0.0024\n",
      "Epoch:  2930 | Loss_ham: 0.0163 | Loss_mod: 0.0023\n",
      "Epoch:  2940 | Loss_ham: 0.0157 | Loss_mod: 0.0031\n",
      "Epoch:  2950 | Loss_ham: 0.0053 | Loss_mod: 0.0032\n",
      "Epoch:  2960 | Loss_ham: 0.0020 | Loss_mod: 0.0033\n",
      "Epoch:  2970 | Loss_ham: 0.0009 | Loss_mod: 0.0033\n",
      "Epoch:  2980 | Loss_ham: 0.0007 | Loss_mod: 0.0030\n",
      "Epoch:  2990 | Loss_ham: 0.0004 | Loss_mod: 0.0029\n",
      "Epoch:  3000 | Loss_ham: 0.0003 | Loss_mod: 0.0027\n",
      "Epoch:  3010 | Loss_ham: 0.0004 | Loss_mod: 0.0026\n",
      "Epoch:  3020 | Loss_ham: 0.0004 | Loss_mod: 0.0026\n",
      "Epoch:  3030 | Loss_ham: 0.0003 | Loss_mod: 0.0026\n",
      "Epoch:  3040 | Loss_ham: 0.0004 | Loss_mod: 0.0025\n",
      "Epoch:  3050 | Loss_ham: 0.0004 | Loss_mod: 0.0025\n",
      "Epoch:  3060 | Loss_ham: 0.0003 | Loss_mod: 0.0024\n",
      "Epoch:  3070 | Loss_ham: 0.0003 | Loss_mod: 0.0024\n",
      "Epoch:  3080 | Loss_ham: 0.0004 | Loss_mod: 0.0023\n",
      "Epoch:  3090 | Loss_ham: 0.0003 | Loss_mod: 0.0022\n",
      "Epoch:  3100 | Loss_ham: 0.0004 | Loss_mod: 0.0021\n",
      "Epoch:  3110 | Loss_ham: 0.0003 | Loss_mod: 0.0021\n",
      "Epoch:  3120 | Loss_ham: 0.0003 | Loss_mod: 0.0021\n",
      "Epoch:  3130 | Loss_ham: 0.0004 | Loss_mod: 0.0020\n",
      "Epoch:  3140 | Loss_ham: 0.0004 | Loss_mod: 0.0020\n",
      "Epoch:  3150 | Loss_ham: 0.0004 | Loss_mod: 0.0021\n",
      "Epoch:  3160 | Loss_ham: 0.0004 | Loss_mod: 0.0020\n",
      "Epoch:  3170 | Loss_ham: 0.0004 | Loss_mod: 0.0019\n",
      "Epoch:  3180 | Loss_ham: 0.0003 | Loss_mod: 0.0019\n",
      "Epoch:  3190 | Loss_ham: 0.0003 | Loss_mod: 0.0018\n",
      "Epoch:  3200 | Loss_ham: 0.0004 | Loss_mod: 0.0018\n",
      "Epoch:  3210 | Loss_ham: 0.0004 | Loss_mod: 0.0018\n",
      "Epoch:  3220 | Loss_ham: 0.0005 | Loss_mod: 0.0018\n",
      "Epoch:  3230 | Loss_ham: 0.0003 | Loss_mod: 0.0017\n",
      "Epoch:  3240 | Loss_ham: 0.0004 | Loss_mod: 0.0017\n",
      "Epoch:  3250 | Loss_ham: 0.0004 | Loss_mod: 0.0017\n",
      "Epoch:  3260 | Loss_ham: 0.0003 | Loss_mod: 0.0017\n",
      "Epoch:  3270 | Loss_ham: 0.0004 | Loss_mod: 0.0017\n",
      "Epoch:  3280 | Loss_ham: 0.0003 | Loss_mod: 0.0017\n",
      "Epoch:  3290 | Loss_ham: 0.0003 | Loss_mod: 0.0016\n",
      "Epoch:  3300 | Loss_ham: 0.0003 | Loss_mod: 0.0016\n",
      "Epoch:  3310 | Loss_ham: 0.0003 | Loss_mod: 0.0015\n",
      "Epoch:  3320 | Loss_ham: 0.0004 | Loss_mod: 0.0015\n",
      "Epoch:  3330 | Loss_ham: 0.0004 | Loss_mod: 0.0015\n",
      "Epoch:  3340 | Loss_ham: 0.0005 | Loss_mod: 0.0015\n",
      "Epoch:  3350 | Loss_ham: 0.0003 | Loss_mod: 0.0015\n",
      "Epoch:  3360 | Loss_ham: 0.0003 | Loss_mod: 0.0014\n",
      "Epoch:  3370 | Loss_ham: 0.0003 | Loss_mod: 0.0015\n",
      "Epoch:  3380 | Loss_ham: 0.0007 | Loss_mod: 0.0014\n",
      "Epoch:  3390 | Loss_ham: 0.0005 | Loss_mod: 0.0014\n",
      "Epoch:  3400 | Loss_ham: 0.0007 | Loss_mod: 0.0014\n",
      "Epoch:  3410 | Loss_ham: 0.0005 | Loss_mod: 0.0014\n",
      "Epoch:  3420 | Loss_ham: 0.0003 | Loss_mod: 0.0014\n",
      "Epoch:  3430 | Loss_ham: 0.0004 | Loss_mod: 0.0013\n",
      "Epoch:  3440 | Loss_ham: 0.0036 | Loss_mod: 0.0014\n",
      "Epoch:  3450 | Loss_ham: 0.0016 | Loss_mod: 0.0014\n",
      "Epoch:  3460 | Loss_ham: 0.0008 | Loss_mod: 0.0014\n",
      "Epoch:  3470 | Loss_ham: 0.0004 | Loss_mod: 0.0013\n",
      "Epoch:  3480 | Loss_ham: 0.0005 | Loss_mod: 0.0014\n",
      "Epoch:  3490 | Loss_ham: 0.0004 | Loss_mod: 0.0013\n",
      "Epoch:  3500 | Loss_ham: 0.0002 | Loss_mod: 0.0013\n",
      "Epoch:  3510 | Loss_ham: 0.0003 | Loss_mod: 0.0013\n",
      "Epoch:  3520 | Loss_ham: 0.0003 | Loss_mod: 0.0013\n",
      "Epoch:  3530 | Loss_ham: 0.0004 | Loss_mod: 0.0013\n",
      "Epoch:  3540 | Loss_ham: 0.0003 | Loss_mod: 0.0012\n",
      "Epoch:  3550 | Loss_ham: 0.0003 | Loss_mod: 0.0013\n",
      "Epoch:  3560 | Loss_ham: 0.0004 | Loss_mod: 0.0013\n",
      "Epoch:  3570 | Loss_ham: 0.0004 | Loss_mod: 0.0013\n",
      "Epoch:  3580 | Loss_ham: 0.0004 | Loss_mod: 0.0012\n",
      "Epoch:  3590 | Loss_ham: 0.0003 | Loss_mod: 0.0012\n",
      "Epoch:  3600 | Loss_ham: 0.0003 | Loss_mod: 0.0012\n",
      "Epoch:  3610 | Loss_ham: 0.0003 | Loss_mod: 0.0013\n",
      "Epoch:  3620 | Loss_ham: 0.0003 | Loss_mod: 0.0012\n",
      "Epoch:  3630 | Loss_ham: 0.0003 | Loss_mod: 0.0012\n",
      "Epoch:  3640 | Loss_ham: 0.0003 | Loss_mod: 0.0012\n",
      "Epoch:  3650 | Loss_ham: 0.0004 | Loss_mod: 0.0012\n",
      "Epoch:  3660 | Loss_ham: 0.0003 | Loss_mod: 0.0012\n",
      "Epoch:  3670 | Loss_ham: 0.0003 | Loss_mod: 0.0012\n",
      "Epoch:  3680 | Loss_ham: 0.0003 | Loss_mod: 0.0012\n",
      "Epoch:  3690 | Loss_ham: 0.0003 | Loss_mod: 0.0012\n",
      "Epoch:  3700 | Loss_ham: 0.0003 | Loss_mod: 0.0012\n",
      "Epoch:  3710 | Loss_ham: 0.0003 | Loss_mod: 0.0012\n",
      "Epoch:  3720 | Loss_ham: 0.0003 | Loss_mod: 0.0011\n",
      "Epoch:  3730 | Loss_ham: 0.0003 | Loss_mod: 0.0011\n",
      "Epoch:  3740 | Loss_ham: 0.0003 | Loss_mod: 0.0011\n",
      "Epoch:  3750 | Loss_ham: 0.0003 | Loss_mod: 0.0011\n",
      "Epoch:  3760 | Loss_ham: 0.0003 | Loss_mod: 0.0011\n",
      "Epoch:  3770 | Loss_ham: 0.0003 | Loss_mod: 0.0011\n",
      "Epoch:  3780 | Loss_ham: 0.0003 | Loss_mod: 0.0011\n",
      "Epoch:  3790 | Loss_ham: 0.0004 | Loss_mod: 0.0011\n",
      "Epoch:  3800 | Loss_ham: 0.0003 | Loss_mod: 0.0011\n",
      "Epoch:  3810 | Loss_ham: 0.0003 | Loss_mod: 0.0011\n",
      "Epoch:  3820 | Loss_ham: 0.0003 | Loss_mod: 0.0011\n",
      "Epoch:  3830 | Loss_ham: 0.0003 | Loss_mod: 0.0010\n",
      "Epoch:  3840 | Loss_ham: 0.0004 | Loss_mod: 0.0011\n",
      "Epoch:  3850 | Loss_ham: 0.0003 | Loss_mod: 0.0011\n",
      "Epoch:  3860 | Loss_ham: 0.0003 | Loss_mod: 0.0010\n",
      "Epoch:  3870 | Loss_ham: 0.0002 | Loss_mod: 0.0011\n",
      "Epoch:  3880 | Loss_ham: 0.0003 | Loss_mod: 0.0011\n",
      "Epoch:  3890 | Loss_ham: 0.0002 | Loss_mod: 0.0010\n",
      "Epoch:  3900 | Loss_ham: 0.0003 | Loss_mod: 0.0010\n",
      "Epoch:  3910 | Loss_ham: 0.0004 | Loss_mod: 0.0010\n",
      "Epoch:  3920 | Loss_ham: 0.0002 | Loss_mod: 0.0010\n",
      "Epoch:  3930 | Loss_ham: 0.0003 | Loss_mod: 0.0010\n",
      "Epoch:  3940 | Loss_ham: 0.0003 | Loss_mod: 0.0010\n",
      "Epoch:  3950 | Loss_ham: 0.0003 | Loss_mod: 0.0010\n",
      "Epoch:  3960 | Loss_ham: 0.0003 | Loss_mod: 0.0010\n",
      "Epoch:  3970 | Loss_ham: 0.0003 | Loss_mod: 0.0010\n",
      "Epoch:  3980 | Loss_ham: 0.0003 | Loss_mod: 0.0010\n",
      "Epoch:  3990 | Loss_ham: 0.0003 | Loss_mod: 0.0010\n",
      "Epoch:  4000 | Loss_ham: 0.0003 | Loss_mod: 0.0010\n",
      "Epoch:  4010 | Loss_ham: 0.0003 | Loss_mod: 0.0010\n",
      "Epoch:  4020 | Loss_ham: 0.0002 | Loss_mod: 0.0010\n",
      "Epoch:  4030 | Loss_ham: 0.0002 | Loss_mod: 0.0009\n",
      "Epoch:  4040 | Loss_ham: 0.0002 | Loss_mod: 0.0009\n",
      "Epoch:  4050 | Loss_ham: 0.0002 | Loss_mod: 0.0009\n",
      "Epoch:  4060 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4070 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4080 | Loss_ham: 0.0003 | Loss_mod: 0.0010\n",
      "Epoch:  4090 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4100 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4110 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4120 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4130 | Loss_ham: 0.0002 | Loss_mod: 0.0009\n",
      "Epoch:  4140 | Loss_ham: 0.0004 | Loss_mod: 0.0010\n",
      "Epoch:  4150 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4160 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4170 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4180 | Loss_ham: 0.0002 | Loss_mod: 0.0009\n",
      "Epoch:  4190 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4200 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4210 | Loss_ham: 0.0002 | Loss_mod: 0.0009\n",
      "Epoch:  4220 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4230 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4240 | Loss_ham: 0.0002 | Loss_mod: 0.0009\n",
      "Epoch:  4250 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4260 | Loss_ham: 0.0004 | Loss_mod: 0.0009\n",
      "Epoch:  4270 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4280 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4290 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4300 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4310 | Loss_ham: 0.0002 | Loss_mod: 0.0009\n",
      "Epoch:  4320 | Loss_ham: 0.0002 | Loss_mod: 0.0009\n",
      "Epoch:  4330 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4340 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4350 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4360 | Loss_ham: 0.0002 | Loss_mod: 0.0009\n",
      "Epoch:  4370 | Loss_ham: 0.0002 | Loss_mod: 0.0009\n",
      "Epoch:  4380 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4390 | Loss_ham: 0.0003 | Loss_mod: 0.0008\n",
      "Epoch:  4400 | Loss_ham: 0.0002 | Loss_mod: 0.0009\n",
      "Epoch:  4410 | Loss_ham: 0.0003 | Loss_mod: 0.0009\n",
      "Epoch:  4420 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4430 | Loss_ham: 0.0003 | Loss_mod: 0.0008\n",
      "Epoch:  4440 | Loss_ham: 0.0002 | Loss_mod: 0.0009\n",
      "Epoch:  4450 | Loss_ham: 0.0003 | Loss_mod: 0.0008\n",
      "Epoch:  4460 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4470 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4480 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4490 | Loss_ham: 0.0003 | Loss_mod: 0.0008\n",
      "Epoch:  4500 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4510 | Loss_ham: 0.0003 | Loss_mod: 0.0008\n",
      "Epoch:  4520 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4530 | Loss_ham: 0.0001 | Loss_mod: 0.0008\n",
      "Epoch:  4540 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4550 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4560 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4570 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4580 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4590 | Loss_ham: 0.0003 | Loss_mod: 0.0008\n",
      "Epoch:  4600 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4610 | Loss_ham: 0.0003 | Loss_mod: 0.0008\n",
      "Epoch:  4620 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4630 | Loss_ham: 0.0003 | Loss_mod: 0.0008\n",
      "Epoch:  4640 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4650 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4660 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4670 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4680 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4690 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4700 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4710 | Loss_ham: 0.0003 | Loss_mod: 0.0008\n",
      "Epoch:  4720 | Loss_ham: 0.0003 | Loss_mod: 0.0008\n",
      "Epoch:  4730 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4740 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4750 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4760 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4770 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4780 | Loss_ham: 0.0003 | Loss_mod: 0.0008\n",
      "Epoch:  4790 | Loss_ham: 0.0003 | Loss_mod: 0.0008\n",
      "Epoch:  4800 | Loss_ham: 0.0003 | Loss_mod: 0.0008\n",
      "Epoch:  4810 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4820 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4830 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4840 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4850 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4860 | Loss_ham: 0.0002 | Loss_mod: 0.0007\n",
      "Epoch:  4870 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4880 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4890 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4900 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4910 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4920 | Loss_ham: 0.0002 | Loss_mod: 0.0007\n",
      "Epoch:  4930 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4940 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4950 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4960 | Loss_ham: 0.0003 | Loss_mod: 0.0008\n",
      "Epoch:  4970 | Loss_ham: 0.0003 | Loss_mod: 0.0007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4980 | Loss_ham: 0.0002 | Loss_mod: 0.0008\n",
      "Epoch:  4990 | Loss_ham: 0.0003 | Loss_mod: 0.0007\n"
     ]
    }
   ],
   "source": [
    "# Training a transformer to minimize PDE losses\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "t = T(w=400)\n",
    "epochs = 5000\n",
    "switch_epoch = 2500\n",
    "lr_decay_epoch = 500\n",
    "\n",
    "n_train = input_.shape[0]\n",
    "batch_size = 128\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(t.parameters(), lr=lr)\n",
    "\n",
    "log = 10\n",
    "\n",
    "losses_ham = [] # hamiltonicity\n",
    "losses_mod = [] # modularity\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    t.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch == 1000 or epoch == 2000:\n",
    "        lr = lr*0.5\n",
    "        optimizer = optim.Adam(t.parameters(), lr=lr)\n",
    "    \n",
    "    choices = np.random.choice(n_train, batch_size)\n",
    "    inputs = input_[choices]\n",
    "    \n",
    "    if epoch == switch_epoch:\n",
    "        for opt_param in optimizer.param_groups:\n",
    "            lr = 1e-3\n",
    "            opt_param['lr'] = lr\n",
    "    \n",
    "    if (epoch+1) % lr_decay_epoch == 0:\n",
    "        for opt_param in optimizer.param_groups:\n",
    "            lr = lr * 0.5\n",
    "            opt_param['lr'] = lr\n",
    "    \n",
    "    if epoch < switch_epoch:\n",
    "        loss_ham = hamiltonicity_loss(f,t,inputs)\n",
    "        loss_mod = float(\"nan\")\n",
    "        losses_ham.append(loss_ham.detach().numpy())\n",
    "        losses_mod.append(loss_mod)\n",
    "        loss = loss_ham\n",
    "    else:\n",
    "        loss_ham = hamiltonicity_loss(f,t,inputs)\n",
    "        loss_mod = modularity_loss(f,t,inputs,n_part=[2,2])\n",
    "        losses_ham.append(loss_ham.detach().numpy())\n",
    "        losses_mod.append(loss_mod.detach().numpy())\n",
    "        loss = loss_ham + loss_mod\n",
    "        \n",
    "    loss.backward(retain_graph=True)\n",
    "    #loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch%log == 0:\n",
    "        print('Epoch:  %d | Loss_ham: %.4f | Loss_mod: %.4f' %(epoch, loss_ham, loss_mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('2d_dp_results/0.1.npy', np.array([np.array(losses_ham),np.array(losses_mod)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = np.load('2d_dp_results/0.1.npy')\n",
    "losses_ham = loss[0]\n",
    "losses_mod = loss[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(epochs), losses_ham, color=\"blue\",alpha=0.7)\n",
    "plt.plot(np.arange(epochs), losses_mod*0.3, color=\"orange\",alpha=0.7)\n",
    "#plt.plot(np.arange(400), losses_tran)\n",
    "#plt.legend([\"hamiltonicity_loss\",\"modularity_loss\"],fontsize=15)\n",
    "plt.xlabel(\"iteration\",fontsize=15)\n",
    "plt.ylabel(\"loss\",fontsize=15)\n",
    "plt.title(\"D. Double Pendulum \"+r\"$(\\theta_0=0.1)$\",fontsize=20)\n",
    "plt.arrow(1100,0.1,0,-0.09,head_width=100,head_length=0.004,linewidth=3, color=\"blue\")\n",
    "plt.text(50,0.2,\"Hamiltonicity \\n      Loss\",fontsize=15, color=\"blue\")\n",
    "plt.arrow(4000,0.1,0,-0.099,head_width=100,head_length=0.0004,linewidth=3, color=\"orange\")\n",
    "plt.text(2500,0.2,\"(2+2)-Modularity Loss\",fontsize=15, color=\"orange\")\n",
    "plt.plot(np.arange(epochs),np.ones(epochs,)*1e-3,ls=\"--\",color=\"black\")\n",
    "plt.yscale('log')\n",
    "plt.savefig(\"../examples/figures/dp.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
