{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Define Transformer: confined to canonical transformation\n",
    "\n",
    "'''class T(nn.Module):\n",
    "    def __init__(self,w=200):\n",
    "        super(T, self).__init__()\n",
    "        self.l1 = nn.Linear(int(input_d/2),w)\n",
    "        self.l2 = nn.Linear(w,w)\n",
    "        self.l3 = nn.Linear(w,int(input_d/2))\n",
    "        \n",
    "    def x_forward(self, xp, eps=0.1):\n",
    "        x = xp[:,:int(input_d/2)]\n",
    "        p = xp[:,int(input_d/2):]\n",
    "        bs = x.shape[0]\n",
    "        f = nn.Tanh()\n",
    "        self.x1 = f(self.l1(x))\n",
    "        self.x2 = f(self.l2(self.x1))\n",
    "        self.x3 = self.l3(self.x2)\n",
    "        xprime = x + eps*self.x3\n",
    "        return xprime\n",
    "    \n",
    "    def jac_tf(self,xp):\n",
    "        x = xp[:,:int(input_d/2)]\n",
    "        p = xp[:,int(input_d/2):]\n",
    "        jac = torch.autograd.functional.jacobian(self.x_forward,x,create_graph=True)\n",
    "        jac_t = []\n",
    "        for i in range(jac.shape[0]):\n",
    "            jac_t.append(jac[i,:,i,:])\n",
    "        jac_t = torch.stack(jac_t)\n",
    "        return jac_t\n",
    "        \n",
    "    def forward(self, xp):\n",
    "        x = xp[:,:int(input_d/2)]\n",
    "        p = xp[:,int(input_d/2):]\n",
    "        jac_t = self.jac_tf(xp)\n",
    "        #print(torch.inverse(jac_t).permute(0,2,1).shape)\n",
    "        #print(p.shape)\n",
    "        pprime = torch.matmul(torch.inverse(jac_t).permute(0,2,1), p.unsqueeze(dim=2))[:,:,0]\n",
    "        xprime = self.x_forward(xp)\n",
    "        return torch.cat((xprime, pprime),dim=1)\n",
    "    \n",
    "    #def forward(self, x, eps=0.0):\n",
    "    #    return self.l0(x)\n",
    "    \n",
    "    def transform_f(self, xp):\n",
    "        jac_t = self.jac_tf(xp)\n",
    "        f_ = f(xp)\n",
    "        fx = f_[:,:int(input_d/2)]\n",
    "        fp = f_[:,int(input_d/2):]\n",
    "        fx_prime = torch.matmul(torch.inverse(jac_t).permute(0,2,1), fx.unsqueeze(dim=2))[:,:,0]\n",
    "        fp_prime = torch.matmul(jac_t, fp.unsqueeze(dim=2))[:,:,0]\n",
    "        return torch.cat((fx_prime, fp_prime),dim=1)'''\n",
    "\n",
    "\n",
    "# Define Transformer: not confined to canonical transformation\n",
    "\n",
    "def batch_jacobian(func, x, create_graph=False):\n",
    "    # x in shape (Batch, Length)\n",
    "    def _func_sum(x):\n",
    "        return func(x).sum(dim=0)\n",
    "    return torch.autograd.functional.jacobian(_func_sum, x, create_graph=create_graph).permute(1,0,2)\n",
    "\n",
    "class T(nn.Module):\n",
    "    def __init__(self,w=200):\n",
    "        super(T, self).__init__()\n",
    "        self.l1 = nn.Linear(input_d,w)\n",
    "        self.l2 = nn.Linear(w,w)\n",
    "        self.l3 = nn.Linear(w,input_d)\n",
    "    \n",
    "    def forward(self, x, eps=0.1):\n",
    "        bs = x.shape[0]\n",
    "        #f = nn.Tanh()\n",
    "        f = nn.SiLU()\n",
    "        self.x1 = f(self.l1(x))\n",
    "        self.x2 = f(self.l2(self.x1))\n",
    "        self.x3 = self.l3(self.x2)\n",
    "        return x + eps*self.x3\n",
    "    \n",
    "    #def forward(self, x, eps=0.0):\n",
    "    #    return self.l0(x)\n",
    "    \n",
    "    def transform_f(self, x):\n",
    "        jac_ts = batch_jacobian(self.forward, x, create_graph=True)\n",
    "        return torch.matmul(jac_ts, torch.unsqueeze(f(x), dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss library\n",
    "\n",
    "# Lie group: for SO(2), g_J = [[0,1],[-1,0]]\n",
    "\n",
    "def Jp_(f,t,inputs):\n",
    "    input_d = input_.shape[1]\n",
    "    jac_f = batch_jacobian(f,inputs,create_graph=True)\n",
    "    jac_ts = batch_jacobian(t,inputs,create_graph=True)\n",
    "    jac_inv_ts = torch.inverse(jac_ts)\n",
    "\n",
    "    # get Hessian of t\n",
    "    gradsss = []\n",
    "    for i in range(input_d):\n",
    "        gradss = []\n",
    "        for j in range(input_d):\n",
    "            grads = torch.autograd.grad(jac_ts[:,i,j], inputs, torch.ones_like(jac_ts[:,i,j]), create_graph=True, retain_graph=True)[0]\n",
    "            gradss.append(grads)\n",
    "        gradss = torch.stack(gradss)\n",
    "        gradsss.append(gradss)\n",
    "    # SHAPE\n",
    "    hess_t = torch.stack(gradsss).permute(2,0,1,3)\n",
    "\n",
    "    # calculate J'\n",
    "    Jp1 = jac_inv_ts.permute(0,2,1).unsqueeze(dim=1).unsqueeze(dim=4)*hess_t.permute(0,2,1,3).unsqueeze(dim=2)*f(inputs).unsqueeze(dim=1).unsqueeze(dim=2).unsqueeze(dim=3)\n",
    "    Jp2 = jac_inv_ts.permute(0,2,1).unsqueeze(dim=1).unsqueeze(dim=4)*jac_ts.unsqueeze(dim=2).unsqueeze(dim=3)*jac_f.permute(0,2,1).unsqueeze(dim=1).unsqueeze(dim=2)\n",
    "    Jp = Jp1 + Jp2\n",
    "    Jp = torch.sum(torch.sum(Jp,dim=4),dim=3)\n",
    "    return Jp\n",
    "\n",
    "def hess(t, inputs):\n",
    "    jac_ts = batch_jacobian(t,inputs,create_graph=True)\n",
    "    \n",
    "    # get Hessian of t\n",
    "    gradsss = []\n",
    "    for i in range(input_d):\n",
    "        gradss = []\n",
    "        for j in range(input_d):\n",
    "            grads = torch.autograd.grad(jac_ts[:,i,j], inputs, torch.ones_like(jac_ts[:,i,j]), create_graph=True, retain_graph=True)[0]\n",
    "            gradss.append(grads)\n",
    "        gradss = torch.stack(gradss)\n",
    "        gradsss.append(gradss)\n",
    "    # SHAPE\n",
    "    hess_t = torch.stack(gradsss).permute(2,0,1,3)\n",
    "    \n",
    "    return hess_t\n",
    "    \n",
    "\n",
    "def off_diag(M,n_part=[2,2]):\n",
    "    bs = M.shape[0]\n",
    "    input_d = M.shape[1]\n",
    "    assert input_d == np.sum(n_part)\n",
    "    start = 0\n",
    "    end = n_part[0]\n",
    "    diag_loss = 0\n",
    "    for i in range(len(n_part)):\n",
    "        diag_loss = diag_loss + torch.sum(M[:,start:end, start:end]**2)\n",
    "        start = end\n",
    "        end = end + n_part[i]\n",
    "    return (torch.sum(M**2) - diag_loss)/(batch_size*input_d**2)\n",
    "\n",
    "\n",
    "def lie_loss(f,t,inputs):\n",
    "    \n",
    "    bs = inputs.shape[0]\n",
    "    # for SO(2)\n",
    "    g_J = torch.tensor([[0,1],[-1,0]], dtype=torch.float, requires_grad=True)\n",
    "    Jp = Jp_(f,t,inputs)\n",
    "    fp = t.transform_f(inputs)\n",
    "    inputsp = torch.unsqueeze(t(inputs), dim=2)\n",
    "    \n",
    "    g_J = torch.unsqueeze(torch.unsqueeze(torch.ones(bs,),dim=1),dim=1) * torch.unsqueeze(g_J, dim=0)\n",
    "    pde = torch.matmul(torch.matmul(Jp.permute(0,1,2),g_J),inputsp) - torch.matmul(g_J, fp)\n",
    "    r_mse = torch.mean(inputsp**2)\n",
    "    loss = torch.mean(pde**2)\n",
    "    return loss/r_mse\n",
    "\n",
    "def translation_loss(f,t,inputs):\n",
    "    Jp = Jp_(f,t,inputs)[:,0]\n",
    "    loss = torch.mean(Jp**2)\n",
    "    return loss\n",
    "\n",
    "def modularity_loss(f,t,inputs,n_part=[2,2]):\n",
    "    Jp = Jp_(f,t,inputs)\n",
    "    loss = off_diag(Jp,n_part=n_part)\n",
    "    return loss\n",
    "\n",
    "def hamiltonicity_loss(f,t,inputs):\n",
    "    Jp = Jp_(f,t,inputs)\n",
    "    input_d = inputs.shape[1]\n",
    "    assert input_d % 2 ==0\n",
    "    M = torch.zeros(input_d, input_d)\n",
    "    half_d = int(input_d/2)\n",
    "    M[:half_d, half_d:] = torch.eye(half_d)\n",
    "    M[half_d:, :half_d] = -torch.eye(half_d)\n",
    "    M = torch.tensor(M, dtype=torch.float, requires_grad=True)\n",
    "    JMMJ = torch.matmul(Jp.permute(0,2,1), M) + torch.matmul(M, Jp)\n",
    "    loss = torch.mean(JMMJ**2)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonical_lie_loss(f,t,inputs):\n",
    "    \n",
    "    bs = inputs.shape[0]\n",
    "    # for SO(2)\n",
    "    g_J = torch.tensor([[0,1],[-1,0]], dtype=torch.float, requires_grad=True)\n",
    "    Jp = Jp_(f,t,inputs)\n",
    "    Jp_xx, Jp_xp, Jp_px, Jp_pp = Jp[:,:2,:2], Jp[:,:2,2:], Jp[:,2:,:2], Jp[:,2:,2:]\n",
    "    fp = t.transform_f(inputs)\n",
    "    fp_p = fp[:,2:]\n",
    "    fp_x = fp[:,:2]\n",
    "    inputsp = torch.unsqueeze(t(inputs), dim=2)\n",
    "    inputsp_x, inputsp_p = inputsp[:,:2], inputsp[:,2:]\n",
    "    \n",
    "    g_J = torch.unsqueeze(torch.unsqueeze(torch.ones(bs,),dim=1),dim=1) * torch.unsqueeze(g_J, dim=0)\n",
    "    \n",
    "    #pde_p = torch.matmul(torch.matmul(Jp_px.permute(0,1,2),g_J),inputsp_x) + torch.matmul(torch.matmul(Jp_pp.permute(0,1,2),g_J),inputsp_p) - torch.matmul(g_J, fp_p.unsqueeze(dim=2))\n",
    "    \n",
    "    #pde_x = torch.matmul(torch.matmul(Jp_xx.permute(0,1,2),g_J),inputsp_x) + torch.matmul(torch.matmul(Jp_xp.permute(0,1,2),g_J),inputsp_p) - torch.matmul(g_J, fp_x.unsqueeze(dim=2))\n",
    "    pde_p = torch.matmul(torch.matmul(Jp_px.permute(0,1,2),g_J),inputsp_x) + torch.matmul(torch.matmul(Jp_pp.permute(0,1,2),g_J),inputsp_p) - torch.matmul(g_J, fp_p)\n",
    "    \n",
    "    pde_x = torch.matmul(torch.matmul(Jp_xx.permute(0,1,2),g_J),inputsp_x) + torch.matmul(torch.matmul(Jp_xp.permute(0,1,2),g_J),inputsp_p) - torch.matmul(g_J, fp_x)\n",
    "    r_mse = torch.mean(inputsp**2)\n",
    "    loss = torch.mean(pde_p**2+pde_x**2)\n",
    "    return loss/r_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Loss_ham: 0.0041 | Loss_lie: nan \n",
      "Epoch:  10 | Loss_ham: 0.0006 | Loss_lie: nan \n",
      "Epoch:  20 | Loss_ham: 0.0002 | Loss_lie: nan \n",
      "Epoch:  30 | Loss_ham: 0.0001 | Loss_lie: nan \n",
      "Epoch:  40 | Loss_ham: 0.0001 | Loss_lie: nan \n",
      "Epoch:  50 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  60 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  70 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  80 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  90 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  100 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  110 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  120 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  130 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  140 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  150 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  160 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  170 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  180 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  190 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  200 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  210 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  220 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  230 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  240 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  250 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  260 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  270 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  280 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  290 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  300 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  310 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  320 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  330 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  340 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  350 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  360 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  370 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  380 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  390 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  400 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  410 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  420 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  430 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  440 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  450 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  460 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  470 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  480 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  490 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  500 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  510 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  520 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  530 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  540 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  550 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  560 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  570 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  580 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  590 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  600 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  610 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  620 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  630 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  640 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  650 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  660 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  670 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  680 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  690 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  700 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  710 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  720 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  730 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  740 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  750 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  760 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  770 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  780 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  790 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  800 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  810 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  820 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  830 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  840 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  850 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  860 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  870 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  880 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  890 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  900 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  910 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  920 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  930 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  940 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  950 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  960 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  970 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  980 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  990 | Loss_ham: 0.0000 | Loss_lie: nan \n",
      "Epoch:  1000 | Loss_ham: 0.0000 | Loss_lie: 0.0713 \n",
      "Epoch:  1010 | Loss_ham: 0.0006 | Loss_lie: 0.0058 \n",
      "Epoch:  1020 | Loss_ham: 0.0004 | Loss_lie: 0.0028 \n",
      "Epoch:  1030 | Loss_ham: 0.0002 | Loss_lie: 0.0009 \n",
      "Epoch:  1040 | Loss_ham: 0.0002 | Loss_lie: 0.0006 \n",
      "Epoch:  1050 | Loss_ham: 0.0001 | Loss_lie: 0.0004 \n",
      "Epoch:  1060 | Loss_ham: 0.0001 | Loss_lie: 0.0002 \n",
      "Epoch:  1070 | Loss_ham: 0.0000 | Loss_lie: 0.0001 \n",
      "Epoch:  1080 | Loss_ham: 0.0000 | Loss_lie: 0.0001 \n",
      "Epoch:  1090 | Loss_ham: 0.0000 | Loss_lie: 0.0001 \n",
      "Epoch:  1100 | Loss_ham: 0.0000 | Loss_lie: 0.0001 \n",
      "Epoch:  1110 | Loss_ham: 0.0000 | Loss_lie: 0.0001 \n",
      "Epoch:  1120 | Loss_ham: 0.0000 | Loss_lie: 0.0001 \n",
      "Epoch:  1130 | Loss_ham: 0.0000 | Loss_lie: 0.0001 \n",
      "Epoch:  1140 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1150 | Loss_ham: 0.0000 | Loss_lie: 0.0001 \n",
      "Epoch:  1160 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1170 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1180 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1190 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1200 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1210 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1220 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1230 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1240 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1250 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1260 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1270 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1280 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1290 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1300 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1310 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1320 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1330 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1340 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1350 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1360 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1370 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1380 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1390 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1400 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1410 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1420 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1430 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1440 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1450 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1460 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1470 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1480 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1490 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1500 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1510 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1520 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1530 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1540 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1550 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1560 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1570 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1580 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1590 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1600 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1610 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1620 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1630 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1640 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1650 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1660 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1670 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1680 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1690 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1700 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1710 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1720 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1730 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1740 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1750 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1760 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1770 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1780 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1790 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1800 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1810 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1820 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1830 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1840 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1850 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1860 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1870 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1880 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1890 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1900 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1910 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1920 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1930 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1940 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1950 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1960 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1970 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1980 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  1990 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2000 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2010 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2020 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2030 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2040 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2050 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2060 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2070 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2080 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2090 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2100 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2110 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2120 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2130 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2140 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2150 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2160 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2170 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2180 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2190 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2200 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2210 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2220 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2230 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2240 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2250 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2260 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2270 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2280 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2290 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2300 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2310 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2320 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2330 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2340 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2350 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2360 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2370 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2380 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2390 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2400 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2410 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2420 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2430 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2440 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2450 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2460 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2470 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2480 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2490 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2500 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2510 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2520 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2530 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2540 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2550 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2560 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2570 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2580 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2590 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2600 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2610 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2620 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2630 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2640 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2650 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2660 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2670 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2680 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2690 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2700 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2710 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2720 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2730 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2740 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2750 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2760 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2770 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2780 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2790 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2800 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2810 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2820 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2830 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2840 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2850 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2860 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2870 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2880 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2890 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2900 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2910 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2920 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2930 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2940 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2950 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2960 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2970 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2980 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  2990 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3000 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3010 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3020 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3030 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3040 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3050 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3060 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3070 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3080 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3090 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3100 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3110 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3120 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3130 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3140 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3150 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3160 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3170 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3180 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3190 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3200 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3210 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3220 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3230 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3240 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3250 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3260 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3270 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3280 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3290 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3300 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3310 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3320 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3330 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3340 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3350 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3360 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3370 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3380 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3390 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3400 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3410 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3420 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3430 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3440 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3450 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3460 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3470 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3480 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3490 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3500 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3510 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3520 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3530 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3540 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3550 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3560 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3570 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3580 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3590 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3600 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3610 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3620 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3630 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3640 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3650 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3660 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3670 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3680 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3690 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3700 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3710 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3720 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3730 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3740 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3750 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3760 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3770 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3780 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3790 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3800 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3810 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3820 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3830 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3840 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3850 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3860 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3870 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3880 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3890 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3900 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3910 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3920 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3930 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3940 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3950 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3960 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3970 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3980 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  3990 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4000 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4010 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4020 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4030 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4040 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4050 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4060 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4070 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4080 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4090 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4100 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4110 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4120 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4130 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4140 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4150 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4160 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4170 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4180 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4190 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4200 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4210 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4220 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4230 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4240 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4250 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4260 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4270 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4280 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4290 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4300 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4310 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4320 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4330 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4340 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4350 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4360 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4370 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4380 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4390 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4400 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4410 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4420 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4430 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4440 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4450 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4460 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4470 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4480 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4490 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4500 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4510 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4520 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4530 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4540 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4550 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4560 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4570 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4580 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4590 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4600 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4610 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4620 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4630 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4640 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4650 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4660 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4670 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4680 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4690 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4700 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4710 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4720 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4730 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4740 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4750 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4760 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4770 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4780 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4790 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4800 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4810 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4820 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4830 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4840 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4850 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4860 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4870 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4880 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4890 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4900 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4910 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4920 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4930 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4940 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4950 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4960 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4970 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4980 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n",
      "Epoch:  4990 | Loss_ham: 0.0000 | Loss_lie: 0.0000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from celluloid import Camera\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "camera = Camera(fig)\n",
    "\n",
    "\n",
    "# Training a transformer to minimize PDE losses\n",
    "\n",
    "# Define Force Field\n",
    "\n",
    "losses = []\n",
    "\n",
    "b = 1\n",
    "a = -2\n",
    "c = 0.1\n",
    "\n",
    "'''def x2xp(x):\n",
    "    y = torch.ones_like(x)\n",
    "    y[:,0] = x[:,0]\n",
    "    y[:,1] = x[:,1]\n",
    "    y[:,2] = x[:,2]\n",
    "    y[:,3] = x[:,3]\n",
    "    return y\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    r = torch.sqrt(x[:,0]**2 + x[:,1]**2)\n",
    "    return torch.transpose(torch.stack([x[:,2],x[:,3],-x[:,0]*r**(a-1)/b,-x[:,1]*r**(a-1)*b]),0,1)\n",
    "'''\n",
    "\n",
    "def x2xp(x):\n",
    "    y = torch.ones_like(x)\n",
    "    y[:,0] = (np.e**(c*x[:,0])-1)/c\n",
    "    y[:,1] = (np.e**(c*x[:,1])-1)/c\n",
    "    y[:,2] = (np.e**(c*x[:,2])-1)/c\n",
    "    y[:,3] = (np.e**(c*x[:,3])-1)/c\n",
    "    return y\n",
    "\n",
    "def f(x):\n",
    "    return torch.transpose(torch.stack([(c*x[:,0]+1)*torch.log(c*x[:,2]+1)/c,(c*x[:,1]+1)*torch.log(c*x[:,3]+1)/c,-(1+c*x[:,2])*torch.log(1+c*x[:,0])/(1/(c**2)*(torch.log(1+c*x[:,0])**2+torch.log(1+c*x[:,1])**2)**(3/2)),-(1+c*x[:,3])*torch.log(1+c*x[:,1])/(1/(c**2)*(torch.log(1+c*x[:,0])**2+torch.log(1+c*x[:,1])**2)**(3/2))]),0,1)\n",
    "\n",
    "\n",
    "input_grid = 4*torch.rand(2000,4, requires_grad=True)-2\n",
    "select = (torch.sqrt(input_grid[:,0]**2 + input_grid[:,1]**2)>1.0)\n",
    "input_grid = input_grid[select]\n",
    "input_ = x2xp(input_grid)\n",
    "input_d = input_.shape[1]\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "t = T(w=400)\n",
    "epochs = 5000\n",
    "switch_epoch = 1000\n",
    "lr_decay_epoch = 500\n",
    "\n",
    "n_train = input_.shape[0]\n",
    "batch_size = 128\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(t.parameters(), lr=lr)\n",
    "\n",
    "log = 10\n",
    "\n",
    "losses_ham = []\n",
    "losses_mod = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    t.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    choices = np.random.choice(n_train, batch_size)\n",
    "    inputs = input_[choices]\n",
    "\n",
    "    if epoch == switch_epoch:\n",
    "        for opt_param in optimizer.param_groups:\n",
    "            lr = 1e-3\n",
    "            opt_param['lr'] = lr\n",
    "    \n",
    "    if (epoch+1) % lr_decay_epoch == 0:\n",
    "        for opt_param in optimizer.param_groups:\n",
    "            lr = lr * 0.5\n",
    "            opt_param['lr'] = lr\n",
    "    '''loss_ham = hamiltonicity_loss(f,t,inputs)\n",
    "    loss = loss_ham\n",
    "\n",
    "    losses_ham.append(loss_ham.detach().numpy())\n",
    "    #loss.backward(retain_graph=True)'''\n",
    "    \n",
    "    if epoch < switch_epoch:\n",
    "        loss_ham = hamiltonicity_loss(f,t,inputs)\n",
    "        loss_mod = float(\"nan\")\n",
    "        losses_ham.append(loss_ham.detach().numpy())\n",
    "        losses_mod.append(loss_mod)\n",
    "        loss = loss_ham\n",
    "    else:\n",
    "        loss_ham = hamiltonicity_loss(f,t,inputs)\n",
    "        loss_mod = canonical_lie_loss(f,t,inputs)\n",
    "        losses_ham.append(loss_ham.detach().numpy())\n",
    "        losses_mod.append(loss_mod.detach().numpy())\n",
    "        loss = loss_ham + loss_mod\n",
    "        \n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%log == 0:\n",
    "        print('Epoch:  %d | Loss_ham: %.4f | Loss_lie: %.4f ' %(epoch, loss_ham, loss_mod))\n",
    "losses.append(loss.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./results/2d_kepler.npy', np.array([losses_ham, losses_mod]))\n",
    "loss = np.load('./results/2d_kepler.npy')\n",
    "losses_ham = loss[0]\n",
    "losses_mod = loss[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hamiltonicity, symplectic equivariance\n",
    "plt.plot(np.arange(epochs),np.array(losses_ham), alpha=0.7,color=\"blue\")\n",
    "plt.plot(np.arange(epochs),np.array(losses_mod), alpha=0.7,color=\"orange\")\n",
    "\n",
    "plt.arrow(500,0.006,0,-0.0059,head_width=20,head_length=0.00001,linewidth=5,color=\"blue\")\n",
    "plt.text(10, 0.01, \"Hamiltonicity Loss\", fontsize=15, color=\"blue\")\n",
    "\n",
    "plt.arrow(3000,0.001,0,-0.00099,head_width=50,head_length=0.000001,linewidth=5,color=\"orange\")\n",
    "plt.text(2000, 0.0015, \"Canonical Eqv Loss\", fontsize=15, color=\"orange\")\n",
    "\n",
    "plt.xlabel(\"iteration\",fontsize=15)\n",
    "plt.ylabel(\"loss\",fontsize=15)\n",
    "#plt.title(\"modularity_loss\",fontsize=15)\n",
    "#plt.legend([\"hamiltonicity_loss\", \"symplectic_rotation_loss\"])\n",
    "plt.plot(np.arange(epochs), np.ones(epochs,)*1e-3, ls=\"--\", color=\"black\")\n",
    "plt.title('C. 2D Kepler',fontsize=20)\n",
    "plt.yscale('log')\n",
    "plt.savefig('./figures/2d_kepler.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./results/2d_kepler.npy', np.array([np.array(losses_ham),np.array(losses_mod)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
